args <- c('./input/rep_time.txt', './output/test') # test input (comment out after test)
del_array <- fread(file = "./input/del.txt", sep = "\t", nThread = 2) # deletion array
input <- read.csv(file = args[1], sep = "\t") # trait data
dat.use <- merge(input, del_array, by = "ID") # merge data (deletion array and trait data)
dat.use <- na.omit(dat.use)
dat.use[, 2] <- scale(dat.use[, 2])
beta <- c(1,2)
is.null(beta)
is.null(beta.init)
exists(beta)
exist(beta)
exists("beta")
exists("beta.init")
setwd("~/iTARGEX/output/fixed_beta_and_lambda")
library(data.table)
library(foreach)
library(doParallel)
library(scales)
args <- c('../../input/rep_time.txt', './output_1') # test input (comment out after test)
del_array <- fread(file = "../../input/del.txt", sep = "\t", nThread = 2) # deletion array
input <- read.csv(file = args[1], sep = "\t") # trait data
dat.use <- merge(input, del_array, by = "ID") # merge data (deletion array and trait data)
dat.use <- na.omit(dat.use)
dat.use[, 2] <- scale(dat.use[, 2])
x <- dat.use[, 2]
y <- dat.use[, -c(1, 2)]
output_dir <- args[2]
param <- read.csv(file = file.path(output_dir, "local_param.csv"), row.names = 1)
weight_c1 <- fread(file = file.path(output_dir, "weight_comp1.csv"), nThread = 2)
weight_c2 <- fread(file = file.path(output_dir, "weight_comp2.csv"), nThread = 2)
typeof(weight_c1)
class(weight_c1)
weight_c1 <- as.numeric(weight_c1)
weight_c1 <- as.martix(weight_c1)
weight_c1 <- as.matrix(weight_c1)
class(weight_c1)
typeof(weight_c1)
weight_c1[1,]
weight_c2[1,]
weight_c1[1,]
weight_c1[2,]
weight_c1 <- as.matrix(fread(file = file.path(output_dir, "weight_comp1.csv"), nThread = 2))
weight_c2 <- as.matrix(fread(file = file.path(output_dir, "weight_comp2.csv"), nThread = 2))
#### correlation computation ####
# p-value computation based on t-test
t_test_pval <- function (n, r) {
pval_tail_1 <- pt(r * sqrt(n - 2) / sqrt(1 - r ^ 2), n - 2)
pval_tail_2 <- 1 - pval_tail_1
2 * min(pval_tail_1, pval_tail_2)
}
test_beta <- function(x, y) {
a <- lm(y ~ x)
summary(a)$coefficients[2, c(1, 4)]
}
#### function for combine the results from parallel processes ####
comb <- function(x, ...) {
mapply(rbind, x, ..., SIMPLIFY=FALSE)
}
cl <- makeCluster(4)
registerDoParallel(cl)
cor_df <- foreach(i = 1: ncol(y), .combine = 'comb', .multicombine = TRUE) %dopar% {
# for (i in 1: ncol(y)) {
# Soft assign
cor_comp1 <- cor(x * weight_c1[i, ], y[, i] * weight_c1[i, ]) # correlation of component_1 computation
cor_comp2 <- cor(x * weight_c2[i, ], y[, i] * weight_c2[i, ]) # correlation of component_2 computation
pval_cor_comp1 <- t_test_pval(n = sample_num, r = cor_comp1)
pval_cor_comp2 <- t_test_pval(n = sample_num, r = cor_comp2)
# Hard assign
comp1_idx <- which(weight_c1[i, ] > 0.5)
comp2_idx <- which(weight_c2[i, ] > 0.5)
cor_comp1 <- cor(x[comp1_idx], y[, i][comp1_idx])
cor_comp2 <- cor(x[comp2_idx], y[, i][comp2_idx])
pval_cor_comp1 <- t_test_pval(n = length(comp1_idx), r = cor_comp1)
pval_cor_comp2 <- t_test_pval(n = length(comp2_idx), r = cor_comp2)
pval_beta_comp1 <- test_beta(x[comp1_idx], y[, i][comp1_idx])
pval_beta_comp2 <- test_beta(x[comp2_idx], y[, i][comp2_idx])
cor_local <- c(cor_comp1, pval_cor_comp1, pval_beta_comp1, cor_comp2, pval_cor_comp2, pval_beta_comp2)
return(cor_local)
# # Combine all data
# cor_df <- rbind(cor_df, cor_local)
}
cor_df <- foreach(i = 1: ncol(y), .combine = 'comb', .multicombine = TRUE) %dopar% {
# for (i in 1: ncol(y)) {
# Soft assign
# cor_comp1 <- cor(x * weight_c1[i, ], y[, i] * weight_c1[i, ]) # correlation of component_1 computation
# cor_comp2 <- cor(x * weight_c2[i, ], y[, i] * weight_c2[i, ]) # correlation of component_2 computation
# pval_cor_comp1 <- t_test_pval(n = sample_num, r = cor_comp1)
# pval_cor_comp2 <- t_test_pval(n = sample_num, r = cor_comp2)
# Hard assign
comp1_idx <- which(weight_c1[i, ] > 0.5)
comp2_idx <- which(weight_c2[i, ] > 0.5)
cor_comp1 <- cor(x[comp1_idx], y[, i][comp1_idx])
cor_comp2 <- cor(x[comp2_idx], y[, i][comp2_idx])
pval_cor_comp1 <- t_test_pval(n = length(comp1_idx), r = cor_comp1)
pval_cor_comp2 <- t_test_pval(n = length(comp2_idx), r = cor_comp2)
pval_beta_comp1 <- test_beta(x[comp1_idx], y[, i][comp1_idx])
pval_beta_comp2 <- test_beta(x[comp2_idx], y[, i][comp2_idx])
cor_local <- c(cor_comp1, pval_cor_comp1, pval_beta_comp1, cor_comp2, pval_cor_comp2, pval_beta_comp2)
return(cor_local)
# # Combine all data
# cor_df <- rbind(cor_df, cor_local)
}
weight_c1 <- fread(file = file.path(output_dir, "weight_comp1.csv"), nThread = 2)
weight_c2 <- fread(file = file.path(output_dir, "weight_comp2.csv"), nThread = 2)
stopCluster(cl)
cor_df <- foreach(i = 1: ncol(y), .combine = 'comb', .multicombine = TRUE) %dopar% {
# for (i in 1: ncol(y)) {
# Soft assign
# cor_comp1 <- cor(x * weight_c1[i, ], y[, i] * weight_c1[i, ]) # correlation of component_1 computation
# cor_comp2 <- cor(x * weight_c2[i, ], y[, i] * weight_c2[i, ]) # correlation of component_2 computation
# pval_cor_comp1 <- t_test_pval(n = sample_num, r = cor_comp1)
# pval_cor_comp2 <- t_test_pval(n = sample_num, r = cor_comp2)
# Hard assign
comp1_idx <- which(weight_c1[i, ] > 0.5)
comp2_idx <- which(weight_c2[i, ] > 0.5)
cor_comp1 <- cor(x[comp1_idx], y[, i][comp1_idx])
cor_comp2 <- cor(x[comp2_idx], y[, i][comp2_idx])
pval_cor_comp1 <- t_test_pval(n = length(comp1_idx), r = cor_comp1)
pval_cor_comp2 <- t_test_pval(n = length(comp2_idx), r = cor_comp2)
pval_beta_comp1 <- test_beta(x[comp1_idx], y[, i][comp1_idx])
pval_beta_comp2 <- test_beta(x[comp2_idx], y[, i][comp2_idx])
cor_local <- c(cor_comp1, pval_cor_comp1, pval_beta_comp1, cor_comp2, pval_cor_comp2, pval_beta_comp2)
return(cor_local)
# # Combine all data
# cor_df <- rbind(cor_df, cor_local)
}
cl <- makeCluster(4)
registerDoParallel(cl)
cor_df <- foreach(i = 1: ncol(y), .combine = 'comb', .multicombine = TRUE) %dopar% {
# for (i in 1: ncol(y)) {
# Soft assign
# cor_comp1 <- cor(x * weight_c1[i, ], y[, i] * weight_c1[i, ]) # correlation of component_1 computation
# cor_comp2 <- cor(x * weight_c2[i, ], y[, i] * weight_c2[i, ]) # correlation of component_2 computation
# pval_cor_comp1 <- t_test_pval(n = sample_num, r = cor_comp1)
# pval_cor_comp2 <- t_test_pval(n = sample_num, r = cor_comp2)
# Hard assign
comp1_idx <- which(weight_c1[i, ] > 0.5)
comp2_idx <- which(weight_c2[i, ] > 0.5)
cor_comp1 <- cor(x[comp1_idx], y[, i][comp1_idx])
cor_comp2 <- cor(x[comp2_idx], y[, i][comp2_idx])
pval_cor_comp1 <- t_test_pval(n = length(comp1_idx), r = cor_comp1)
pval_cor_comp2 <- t_test_pval(n = length(comp2_idx), r = cor_comp2)
pval_beta_comp1 <- test_beta(x[comp1_idx], y[, i][comp1_idx])
pval_beta_comp2 <- test_beta(x[comp2_idx], y[, i][comp2_idx])
cor_local <- c(cor_comp1, pval_cor_comp1, pval_beta_comp1, cor_comp2, pval_cor_comp2, pval_beta_comp2)
return(cor_local)
# # Combine all data
# cor_df <- rbind(cor_df, cor_local)
}
weight_c1 <- as.matrix(fread(file = file.path(output_dir, "weight_comp1.csv"), nThread = 2))
weight_c2 <- as.matrix(fread(file = file.path(output_dir, "weight_comp2.csv"), nThread = 2))
stopCluster(cl)
cl <- makeCluster(4)
registerDoParallel(cl)
cor_df <- foreach(i = 1: ncol(y), .combine = 'comb', .multicombine = TRUE) %dopar% {
# for (i in 1: ncol(y)) {
# Soft assign
# cor_comp1 <- cor(x * weight_c1[i, ], y[, i] * weight_c1[i, ]) # correlation of component_1 computation
# cor_comp2 <- cor(x * weight_c2[i, ], y[, i] * weight_c2[i, ]) # correlation of component_2 computation
# pval_cor_comp1 <- t_test_pval(n = sample_num, r = cor_comp1)
# pval_cor_comp2 <- t_test_pval(n = sample_num, r = cor_comp2)
# Hard assign
comp1_idx <- which(weight_c1[i, ] > 0.5)
comp2_idx <- which(weight_c2[i, ] > 0.5)
cor_comp1 <- cor(x[comp1_idx], y[, i][comp1_idx])
cor_comp2 <- cor(x[comp2_idx], y[, i][comp2_idx])
pval_cor_comp1 <- t_test_pval(n = length(comp1_idx), r = cor_comp1)
pval_cor_comp2 <- t_test_pval(n = length(comp2_idx), r = cor_comp2)
pval_beta_comp1 <- test_beta(x[comp1_idx], y[, i][comp1_idx])
pval_beta_comp2 <- test_beta(x[comp2_idx], y[, i][comp2_idx])
cor_local <- c(cor_comp1, pval_cor_comp1, pval_beta_comp1, cor_comp2, pval_cor_comp2, pval_beta_comp2)
return(cor_local)
# # Combine all data
# cor_df <- rbind(cor_df, cor_local)
}
cor_df
View(cor_df)
cor_df <- as.data.frame(cor_df, row.names = colnames(y)[1: ncol(y)])
View(cor_df)
colnames(cor_df) <- c("cor_c1", "pval_cor_c1", "beta_c1", "pval_beta_c1",
"cor_c2", "pval_cor_c2", "beta_c2", "pval_beta_c2")
i = 1
lm(y[, i]~x, weights = weight_c1[i, ])
summary(lm(y[, i]~x, weights = weight_c1[i, ]))$coef
param[i,]
summary(lm(y[, i]~x, weights = weight_c2[i, ]))$coef
# Soft assign
cor_comp1 <- cor(x * weight_c1[i, ], y[, i] * weight_c1[i, ]) # correlation of component_1 computation
cor_comp2 <- cor(x * weight_c2[i, ], y[, i] * weight_c2[i, ]) # correlation of component_2 computation
pval_cor_comp1 <- t_test_pval(n = sample_num, r = cor_comp1)
sample_num = 6107
pval_cor_comp1 <- t_test_pval(n = sample_num, r = cor_comp1)
pval_cor_comp2 <- t_test_pval(n = sample_num, r = cor_comp2)
# Hard assign
comp1_idx <- which(weight_c1[i, ] > 0.5)
comp2_idx <- which(weight_c2[i, ] > 0.5)
cor_comp1 <- cor(x[comp1_idx], y[, i][comp1_idx])
cor_comp2 <- cor(x[comp2_idx], y[, i][comp2_idx])
pval_cor_comp1 <- t_test_pval(n = length(comp1_idx), r = cor_comp1)
pval_cor_comp2 <- t_test_pval(n = length(comp2_idx), r = cor_comp2)
pval_beta_comp1 <- test_beta(x[comp1_idx], y[, i][comp1_idx])
pval_beta_comp2 <- test_beta(x[comp2_idx], y[, i][comp2_idx])
pval_beta_comp1
# Soft assign
cor_comp1 <- cor(x * weight_c1[i, ], y[, i] * weight_c1[i, ]) # correlation of component_1 computation
cor_comp2 <- cor(x * weight_c2[i, ], y[, i] * weight_c2[i, ]) # correlation of component_2 computation
pval_cor_comp1 <- t_test_pval(n = sample_num, r = cor_comp1)
pval_cor_comp2 <- t_test_pval(n = sample_num, r = cor_comp2)
lm(y[i] ~ x, weights = weight_c1[i, ])
lm(y[, i] ~ x, weights = weight_c1[i, ])
summary(lm(y[, i] ~ x, weights = weight_c1[i, ]))$coef
# Hard assign
comp1_idx <- which(weight_c1[i, ] > 0.5)
comp2_idx <- which(weight_c2[i, ] > 0.5)
cor_comp1 <- cor(x[comp1_idx], y[, i][comp1_idx])
cor_comp2 <- cor(x[comp2_idx], y[, i][comp2_idx])
pval_cor_comp1 <- t_test_pval(n = length(comp1_idx), r = cor_comp1)
pval_cor_comp2 <- t_test_pval(n = length(comp2_idx), r = cor_comp2)
pval_beta_comp1 <- test_beta(x[comp1_idx], y[, i][comp1_idx])
pval_beta_comp2 <- test_beta(x[comp2_idx], y[, i][comp2_idx])
cor_local <- c(cor_comp1, pval_cor_comp1, pval_beta_comp1, cor_comp2, pval_cor_comp2, pval_beta_comp2)
# Soft assign
cor_comp1 <- cor(x * weight_c1[i, ], y[, i] * weight_c1[i, ]) # correlation of component_1 computation
cor_comp2 <- cor(x * weight_c2[i, ], y[, i] * weight_c2[i, ]) # correlation of component_2 computation
pval_cor_comp1 <- t_test_pval(n = sample_num, r = cor_comp1)
pval_cor_comp2 <- t_test_pval(n = sample_num, r = cor_comp2)
lm(y[i,] ~ x, weights = weight_c1[i, ])
summary(lm(y[, i] ~ x, weights = weight_c1[i, ]))$coef
# Hard assign
comp1_idx <- which(weight_c1[i, ] > 0.5)
comp2_idx <- which(weight_c2[i, ] > 0.5)
cor_comp1 <- cor(x[comp1_idx], y[, i][comp1_idx])
cor_comp2 <- cor(x[comp2_idx], y[, i][comp2_idx])
# pval_cor_comp1 <- t_test_pval(n = length(comp1_idx), r = cor_comp1)
# pval_cor_comp2 <- t_test_pval(n = length(comp2_idx), r = cor_comp2)
pval_beta_comp1 <- test_beta(x[comp1_idx], y[, i][comp1_idx])
pval_beta_comp2 <- test_beta(x[comp2_idx], y[, i][comp2_idx])
test_beta <- function(x, y, weights = NULL) {
a <- lm(y ~ x, weights = weights)
summary(a)$coefficients[2, c(1, 4)]
}
# Hard assign
comp1_idx <- which(weight_c1[i, ] > 0.5)
comp2_idx <- which(weight_c2[i, ] > 0.5)
cor_comp1 <- cor(x[comp1_idx], y[, i][comp1_idx])
cor_comp2 <- cor(x[comp2_idx], y[, i][comp2_idx])
# pval_cor_comp1 <- t_test_pval(n = length(comp1_idx), r = cor_comp1)
# pval_cor_comp2 <- t_test_pval(n = length(comp2_idx), r = cor_comp2)
pval_beta_comp1 <- test_beta(x[comp1_idx], y[, i][comp1_idx])
pval_beta_comp2 <- test_beta(x[comp2_idx], y[, i][comp2_idx])
# Hard assign
comp1_idx <- which(weight_c1[i, ] > 0.5)
comp2_idx <- which(weight_c2[i, ] > 0.5)
cor_comp1 <- cor(x[comp1_idx], y[, i][comp1_idx])
cor_comp2 <- cor(x[comp2_idx], y[, i][comp2_idx])
pval_cor_comp1 <- t_test_pval(n = length(comp1_idx), r = cor_comp1)
pval_cor_comp2 <- t_test_pval(n = length(comp2_idx), r = cor_comp2)
pval_beta_comp1 <- test_beta(x[comp1_idx], y[, i][comp1_idx])
pval_beta_comp2 <- test_beta(x[comp2_idx], y[, i][comp2_idx])
# Soft assign
cor_comp1 <- cor(x * weight_c1[i, ], y[, i] * weight_c1[i, ])
cor_comp2 <- cor(x * weight_c2[i, ], y[, i] * weight_c2[i, ])
pval_beta_comp1 <- test_beta(x, y[, i], weights = weight_c1[i, ])
pval_beta_comp2 <- test_beta(x, y[, i], weights = weight_c2[i, ])
param[i,]
# Soft assign
cor_comp1 <- cor(x * weight_c1[i, ], y[, i] * weight_c1[i, ])
cor_comp2 <- cor(x * weight_c2[i, ], y[, i] * weight_c2[i, ])
pval_beta_comp1 <- test_beta(x, y[, i], weights = weight_c1[i, ])
pval_beta_comp2 <- test_beta(x, y[, i], weights = weight_c2[i, ])
# pval_cor_comp1 <- t_test_pval(n = sample_num, r = cor_comp1)
# pval_cor_comp2 <- t_test_pval(n = sample_num, r = cor_comp2)
cor_local <- c(cor_comp1, pval_beta_comp1, cor_comp2, pval_beta_comp2)
# Hard assign
comp1_idx <- which(weight_c1[i, ] > 0.5)
comp2_idx <- which(weight_c2[i, ] > 0.5)
cor_comp1 <- cor(x[comp1_idx], y[, i][comp1_idx])
cor_comp2 <- cor(x[comp2_idx], y[, i][comp2_idx])
# pval_cor_comp1 <- t_test_pval(n = length(comp1_idx), r = cor_comp1)
# pval_cor_comp2 <- t_test_pval(n = length(comp2_idx), r = cor_comp2)
pval_beta_comp1 <- test_beta(x[comp1_idx], y[, i][comp1_idx])
pval_beta_comp2 <- test_beta(x[comp2_idx], y[, i][comp2_idx])
cor_local
cor_local <- cbind(cor_local, cor_comp1, pval_beta_comp1, cor_comp2, pval_beta_comp2)
View(cor_local)
# Soft assign
cor_comp1 <- cor(x * weight_c1[i, ], y[, i] * weight_c1[i, ])
cor_comp2 <- cor(x * weight_c2[i, ], y[, i] * weight_c2[i, ])
pval_beta_comp1 <- test_beta(x, y[, i], weights = weight_c1[i, ])
pval_beta_comp2 <- test_beta(x, y[, i], weights = weight_c2[i, ])
# pval_cor_comp1 <- t_test_pval(n = sample_num, r = cor_comp1)
# pval_cor_comp2 <- t_test_pval(n = sample_num, r = cor_comp2)
cor_local <- c(cor_comp1, pval_beta_comp1, cor_comp2, pval_beta_comp2)
# Hard assign
comp1_idx <- which(weight_c1[i, ] > 0.5)
comp2_idx <- which(weight_c2[i, ] > 0.5)
cor_comp1 <- cor(x[comp1_idx], y[, i][comp1_idx])
cor_comp2 <- cor(x[comp2_idx], y[, i][comp2_idx])
# pval_cor_comp1 <- t_test_pval(n = length(comp1_idx), r = cor_comp1)
# pval_cor_comp2 <- t_test_pval(n = length(comp2_idx), r = cor_comp2)
pval_beta_comp1 <- test_beta(x[comp1_idx], y[, i][comp1_idx])
pval_beta_comp2 <- test_beta(x[comp2_idx], y[, i][comp2_idx])
cor_local <- cbind(cor_local, c(cor_comp1, pval_beta_comp1, cor_comp2, pval_beta_comp2))
View(cor_local)
# Soft assign
cor_comp1 <- cor(x * weight_c1[i, ], y[, i] * weight_c1[i, ])
cor_comp2 <- cor(x * weight_c2[i, ], y[, i] * weight_c2[i, ])
pval_beta_comp1 <- test_beta(x, y[, i], weights = weight_c1[i, ])
pval_beta_comp2 <- test_beta(x, y[, i], weights = weight_c2[i, ])
# pval_cor_comp1 <- t_test_pval(n = sample_num, r = cor_comp1)
# pval_cor_comp2 <- t_test_pval(n = sample_num, r = cor_comp2)
cor_local <- c(cor_comp1, pval_beta_comp1, cor_comp2, pval_beta_comp2)
# Hard assign
comp1_idx <- which(weight_c1[i, ] > 0.5)
comp2_idx <- which(weight_c2[i, ] > 0.5)
cor_comp1 <- cor(x[comp1_idx], y[, i][comp1_idx])
cor_comp2 <- cor(x[comp2_idx], y[, i][comp2_idx])
# pval_cor_comp1 <- t_test_pval(n = length(comp1_idx), r = cor_comp1)
# pval_cor_comp2 <- t_test_pval(n = length(comp2_idx), r = cor_comp2)
pval_beta_comp1 <- test_beta(x[comp1_idx], y[, i][comp1_idx])
pval_beta_comp2 <- test_beta(x[comp2_idx], y[, i][comp2_idx])
cor_local
cor_local <- c(cor_local, cor_comp1, pval_beta_comp1, cor_comp2, pval_beta_comp2)
cor_local
library(data.table)
library(foreach)
library(doParallel)
library(scales)
args <- commandArgs(trailingOnly = TRUE) # Input 2 arguments. return vector with (input, output)
args <- c('../../input/rep_time.txt', './output_1') # test input (comment out after test)
del_array <- fread(file = "../../input/del.txt", sep = "\t", nThread = 2) # deletion array
input <- read.csv(file = args[1], sep = "\t") # trait data
dat.use <- merge(input, del_array, by = "ID") # merge data (deletion array and trait data)
dat.use <- na.omit(dat.use)
dat.use[, 2] <- scale(dat.use[, 2])
x <- dat.use[, 2]
y <- dat.use[, -c(1, 2)]
output_dir <- args[2]
param <- read.csv(file = file.path(output_dir, "local_param.csv"), row.names = 1)
weight_c1 <- as.matrix(fread(file = file.path(output_dir, "weight_comp1.csv"), nThread = 2))
weight_c2 <- as.matrix(fread(file = file.path(output_dir, "weight_comp2.csv"), nThread = 2))
#### correlation computation ####
# p-value computation based on t-test
t_test_pval <- function (n, r) {
pval_tail_1 <- pt(r * sqrt(n - 2) / sqrt(1 - r ^ 2), n - 2)
pval_tail_2 <- 1 - pval_tail_1
2 * min(pval_tail_1, pval_tail_2)
}
test_beta <- function(x, y, weights = NULL) {
a <- lm(y ~ x, weights = weights)
summary(a)$coefficients[2, c(1, 4)]
}
#### function for combine the results from parallel processes ####
comb <- function(x, ...) {
mapply(rbind, x, ..., SIMPLIFY=FALSE)
}
cl <- makeCluster(4)
registerDoParallel(cl)
cor_df <- foreach(i = 1: ncol(y), .combine = 'comb', .multicombine = TRUE) %dopar% {
# for (i in 1: ncol(y)) {
# Soft assign
cor_comp1 <- cor(x * weight_c1[i, ], y[, i] * weight_c1[i, ])
cor_comp2 <- cor(x * weight_c2[i, ], y[, i] * weight_c2[i, ])
# pval_cor_comp1 <- t_test_pval(n = sample_num, r = cor_comp1)
# pval_cor_comp2 <- t_test_pval(n = sample_num, r = cor_comp2)
pval_comp1 <- test_beta(x, y[, i], weights = weight_c1[i, ])
pval_comp2 <- test_beta(x, y[, i], weights = weight_c2[i, ])
cor_local <- c(cor_comp1, pval_beta_comp1, cor_comp2, pval_beta_comp2)
# Hard assign
comp1_idx <- which(weight_c1[i, ] > 0.5)
comp2_idx <- which(weight_c2[i, ] > 0.5)
cor_comp1 <- cor(x[comp1_idx], y[, i][comp1_idx])
cor_comp2 <- cor(x[comp2_idx], y[, i][comp2_idx])
# pval_cor_comp1 <- t_test_pval(n = length(comp1_idx), r = cor_comp1)
# pval_cor_comp2 <- t_test_pval(n = length(comp2_idx), r = cor_comp2)
pval_comp1 <- test_beta(x[comp1_idx], y[, i][comp1_idx])
pval_comp2 <- test_beta(x[comp2_idx], y[, i][comp2_idx])
cor_local <- c(cor_local, cor_comp1, pval_beta_comp1, cor_comp2, pval_beta_comp2)
return(cor_local)
# # Combine all data
# cor_df <- rbind(cor_df, cor_local)
}
stopCluster(cl)
cl <- makeCluster(4)
registerDoParallel(cl)
cor_df <- foreach(i = 1: ncol(y), .combine = 'comb', .multicombine = TRUE) %dopar% {
# for (i in 1: ncol(y)) {
# Soft assign
cor_comp1 <- cor(x * weight_c1[i, ], y[, i] * weight_c1[i, ])
cor_comp2 <- cor(x * weight_c2[i, ], y[, i] * weight_c2[i, ])
# pval_cor_comp1 <- t_test_pval(n = sample_num, r = cor_comp1)
# pval_cor_comp2 <- t_test_pval(n = sample_num, r = cor_comp2)
pval_comp1 <- test_beta(x, y[, i], weights = weight_c1[i, ])
pval_comp2 <- test_beta(x, y[, i], weights = weight_c2[i, ])
cor_local <- c(cor_comp1, pval_comp1, cor_comp2, pval_comp2)
# Hard assign
comp1_idx <- which(weight_c1[i, ] > 0.5)
comp2_idx <- which(weight_c2[i, ] > 0.5)
cor_comp1 <- cor(x[comp1_idx], y[, i][comp1_idx])
cor_comp2 <- cor(x[comp2_idx], y[, i][comp2_idx])
# pval_cor_comp1 <- t_test_pval(n = length(comp1_idx), r = cor_comp1)
# pval_cor_comp2 <- t_test_pval(n = length(comp2_idx), r = cor_comp2)
pval_comp1 <- test_beta(x[comp1_idx], y[, i][comp1_idx])
pval_comp2 <- test_beta(x[comp2_idx], y[, i][comp2_idx])
cor_local <- c(cor_local, cor_comp1, pval_comp1, cor_comp2, pval_comp2)
return(cor_local)
# # Combine all data
# cor_df <- rbind(cor_df, cor_local)
}
stopCluster(cl)
cor_df <- as.data.frame(cor_df, row.names = colnames(y)[1: ncol(y)])
colnames(cor_df) <- c("soft_cor_c1", "soft_beta_c1", "soft_pval_c1",
"soft_cor_c2", "soft_beta_c2", "soft_pval_c2",
"hard_cor_c1", "hard_beta_c1", "hard_pval_c1",
"hard_cor_c2", "hard_beta_c2", "hard_pval_c2")
# Apply Bonferroni correction to p-value
pval_adj_df <- sapply(cor_df[, c(3, 6, 9, 12)], p.adjust, method = "bonferroni")
colnames(pval_adj_df) <- c("soft_adjp_c1", "soft_adjp_c2", "hard_adjp_c1", "hard_adjp_c2")
cor_df <- cbind(cor_df, pval_adj_df)
View(cor_df)
# -log10(p-value) transformation
logp_df <- sapply(cor_df[, c(13: 16)], log10) * (-1) # apply -log10 transformation to dataframe
logp_df[is.infinite(logp_df)] <- 350 # Set the p-value with infinite value to 350
cor_df[, c(13: 16)] <- logp_df
param[1,]
# Select and output the significant cases
cor_sig_c1 <- subset(cor_df, soft_adjp_c1 > -log10(0.01),
select = c(1: 3, 13, 17))
# Select and output the significant cases
cor_sig_c1 <- subset(cor_df, soft_adjp_c1 > -log10(0.01),
select = c(1: 3, 13, 17))
View(cor_df)
# Select and output the significant cases
cor_sig_c1 <- subset(cor_df, soft_adjp_c1 > -log10(0.01), select = c(1: 3, 13, 17))
c(1: 3, 13, 17)
?subset
subset(cor_df, soft_adjp_c1 > -log10(0.01), select = c(1: 3, 13, 17))
View(cor_df)
cor_df
cor_df[1]
cor_df[2]
cor_df[3]
cor_df[18]
cor_df[17]
# Concatenate more information to the dataframe
cor_df <- cbind(cor_df, param$lambda_1, param$lambda_2)
colnames(cor_df)[c(17, 18)] <- c("ratio_1", "ratio_2")
# Select and output the significant cases
cor_sig_c1 <- subset(cor_df, soft_adjp_c1 > -log10(0.01), select = c(1: 3, 13, 17))
View(cor_sig_c1)
